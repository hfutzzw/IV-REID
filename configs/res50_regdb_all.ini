[DATA]
# Size of the image during training
SIZE_TRAIN = 384, 128
# Size of the image during test
SIZE_TEST  = 384, 128
# Random probability for image horizontal flip
FLIP_PROB = 0.5
# Random probability for random erasing
RE_PROB = 0
# Values to be used for image normalization
NORMALIZATION_MEAN = 0.485, 0.456, 0.406
# Values to be used for image normalization
NORMALIZATION_STD  = 0.229, 0.224, 0.225
# Value of padding size
PADDING = 10
# Number of data loading threads
NUM_WORKERS = 8
# Sampler for data loading[random, balanced]
SAMPLER = balanced
COLLATE_FN = org
# Number of images per batch
TRAIN_BATCH_SIZE = 64
SAMPLE_ID_INSTANCE = 4
TEST_BATCH_SIZE  = 64

DATASET_NAME = RegDB

[MODEL]
# Using device
DEVICE = cuda
# ID number of GPU
DEVICE_ID = 2
# Name of backbone
NAME = resnet50
# Last stride of backbone
LAST_STRIDE = 1
# Path to pretrained model of backbone
PRETRAIN_PATH = /home/lyq/.torch/models/resnet50-19c8e357.pth
# Path to save model and logger
OUTPUT_PATH = ./output/res50_regdb
# Logger Info
LOGGER_NAME = res50_regdb_all

# If use bias in last fc layer
FC_BIAS = yes
# If use Norm layer before fc layer
USING_NORM = yes
# norm layer type: [bn: batch normalization, gn: group normalization]
NORM_TYPE = bn
# random seed for shuffle data
SEED = 2019

[TRAIN]
LOSS_TYPE = softmax_triplet

OPTIMAZER = Adam
# Number of max epoches
MAX_EPOCHS = 100
# Base learning rate
BASE_LR = 1e-4
# Factor of learning bias
BIAS_LR_FACTOR = 1
# Momentum
MOMENTUM = 0.9
# Settings of weight decay
WEIGHT_DECAY = 0.0005
WEIGHT_DECAY_BIAS = 0.

# decay rate of learning rate
GAMMA = 0.1
# decay step of learning rate
STEPS = 30

# epoch number of saving checkpoints
CHECKPOINT_PERIOD = 10
# epoch number of validation
EVAL_PERIOD = 2

# Margin of triplet loss
MARGIN = 0.2
